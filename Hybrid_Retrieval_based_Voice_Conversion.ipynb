{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/7exe/HRVC/blob/main/Hybrid_Retrieval_based_Voice_Conversion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install torch torchaudio torchcrepe librosa soundfile numpy tqdm einops\n",
        "\n",
        "# (Optional) clone your repo or create workspace\n",
        "!mkdir -p v2v_project && cd v2v_project\n"
      ],
      "metadata": {
        "id": "8gh425MPv5H9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccaf5a31-6cd5-4277-c086-0750f4b66cd7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Collecting torchcrepe\n",
            "  Downloading torchcrepe-0.0.24-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (0.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Collecting resampy (from torchcrepe)\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torchcrepe) (1.16.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.0.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile) (2.23)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (2.32.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.8.3)\n",
            "Downloading torchcrepe-0.0.24-py3-none-any.whl (72.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.3/72.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m115.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: resampy, torchcrepe\n",
            "Successfully installed resampy-0.4.3 torchcrepe-0.0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "import torchaudio\n",
        "import torchcrepe\n",
        "import librosa, soundfile as sf\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omQKWQqH0gJ-",
        "outputId": "aaea8de2-538e-4259-ec00-bc650c25d97f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Core modules ===\n",
        "\n",
        "class TimbreStyleEncoder(nn.Module):\n",
        "    def __init__(self, dim=128, model_dim=192, depth=2, nhead=4):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Linear(80, model_dim)\n",
        "        self.blocks = nn.ModuleList([\n",
        "            nn.TransformerEncoderLayer(model_dim, nhead, dim_feedforward=model_dim*4, batch_first=True, activation=\"gelu\")\n",
        "            for _ in range(depth)\n",
        "        ])\n",
        "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.proj = nn.Linear(model_dim, dim)\n",
        "\n",
        "    def forward(self, mel):\n",
        "        x = self.inp(mel)\n",
        "        for blk in self.blocks:\n",
        "            x = blk(x)\n",
        "        x = x.transpose(1, 2)\n",
        "        x = self.pool(x).squeeze(-1)\n",
        "        return F.layer_norm(self.proj(x), [self.proj.out_features])\n",
        "\n",
        "\n",
        "class ProsodyPrototype(nn.Module):\n",
        "    \"\"\"Learned accent/prosody prototype vector.\"\"\"\n",
        "    def __init__(self, dim=128):\n",
        "        super().__init__()\n",
        "        self.proto = nn.Parameter(torch.randn(1, dim))\n",
        "\n",
        "    def forward(self, B, T):\n",
        "        return self.proto.expand(B, T, -1)\n",
        "\n",
        "\n",
        "class UnitF0EnergyToMel(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim=80, model_dim=384, depth=6, nhead=6, ff_mult=4, timbre_dim=128, prosody_dim=128):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Linear(in_dim + timbre_dim + prosody_dim, model_dim)\n",
        "        self.pe = nn.Parameter(torch.randn(1, 2048, model_dim))\n",
        "        self.blocks = nn.ModuleList([\n",
        "            nn.TransformerEncoderLayer(model_dim, nhead, dim_feedforward=model_dim*ff_mult, batch_first=True, activation=\"gelu\")\n",
        "            for _ in range(depth)\n",
        "        ])\n",
        "        self.out = nn.Linear(model_dim, out_dim)\n",
        "\n",
        "    def forward(self, units, logf0, energy, timbre, prosody_proto):\n",
        "        B, T, _ = units.shape\n",
        "        x = torch.cat([units, logf0.unsqueeze(-1), energy.unsqueeze(-1), timbre.unsqueeze(1).expand(-1, T, -1), prosody_proto], dim=-1)\n",
        "        x = self.inp(x) + self.pe[:, :T]\n",
        "        for blk in self.blocks:\n",
        "            x = blk(x)\n",
        "        return self.out(x)\n"
      ],
      "metadata": {
        "id": "XzkPSTB808yF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_mel(wav, sr=16000, n_mels=80):\n",
        "    mel = torchaudio.transforms.MelSpectrogram(\n",
        "        sample_rate=sr, n_fft=1024, hop_length=256, n_mels=n_mels\n",
        "    )(torch.tensor(wav).unsqueeze(0))\n",
        "    mel = torchaudio.functional.amplitude_to_DB(mel, multiplier=20.0, amin=1e-5, db_multiplier=0.0)\n",
        "    return mel.squeeze(0).T  # (T, 80)\n",
        "\n",
        "def extract_f0_energy(wav, sr=16000):\n",
        "    wav_t = torch.tensor(wav).float().to(device).unsqueeze(0)\n",
        "    f0 = torchcrepe.predict(\n",
        "        wav_t, sr, 256, fmin=50, fmax=550, model=\"full\", device=device, return_periodicity=False\n",
        "    ).squeeze(0)\n",
        "    logf0 = torch.log(f0 + 1e-6).cpu()\n",
        "    energy = torch.log(torch.clamp(torch.tensor(librosa.feature.rms(y=wav, frame_length=1024, hop_length=256)[0]), min=1e-6))\n",
        "    return logf0, torch.tensor(energy)\n"
      ],
      "metadata": {
        "id": "6xu3W5cQ1AGj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simplified unsupervised loop (fill with your dataset loader)\n",
        "\n",
        "timbre_enc = TimbreStyleEncoder().to(device)\n",
        "prosody_proto = ProsodyPrototype().to(device)\n",
        "generator = UnitF0EnergyToMel(in_dim=256).to(device)  # assuming HuBERT gives 256-dim units\n",
        "\n",
        "params = list(generator.parameters()) + list(timbre_enc.parameters()) + list(prosody_proto.parameters())\n",
        "optim = torch.optim.Adam(params, lr=2e-4)\n",
        "\n",
        "for epoch in range(1):  # increase as needed\n",
        "    # TODO: replace with real dataset loop\n",
        "    wav, sr = librosa.load(librosa.example(\"trumpet\"), sr=16000)\n",
        "    mel = extract_mel(wav).to(device)\n",
        "    logf0, energy = extract_f0_energy(wav)\n",
        "\n",
        "    # dummy HuBERT-like units (replace with pretrained HuBERT extraction)\n",
        "    units = torch.randn(mel.shape[0], 256).unsqueeze(0).to(device)\n",
        "\n",
        "    timbre = timbre_enc(mel.unsqueeze(0).to(device))\n",
        "    pros = prosody_proto(B=1, T=units.shape[1])\n",
        "\n",
        "    mel_hat = generator(units, logf0.unsqueeze(0).to(device), energy.unsqueeze(0).to(device), timbre, pros)\n",
        "\n",
        "    loss = F.l1_loss(mel_hat, mel.unsqueeze(0).to(device))\n",
        "    optim.zero_grad(); loss.backward(); optim.step()\n",
        "    print(\"Loss:\", loss.item())\n"
      ],
      "metadata": {
        "id": "FVIAxjK81Dkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_voice(src_wav, ref_wav, sr=16000):\n",
        "    # load\n",
        "    src, _ = librosa.load(src_wav, sr=sr)\n",
        "    ref, _ = librosa.load(ref_wav, sr=sr)\n",
        "\n",
        "    src_mel = extract_mel(src)\n",
        "    src_logf0, src_energy = extract_f0_energy(src)\n",
        "\n",
        "    ref_mel = extract_mel(ref).to(device)\n",
        "    timbre = timbre_enc(ref_mel.unsqueeze(0)).to(device)\n",
        "\n",
        "    units = torch.randn(src_mel.shape[0], 256).unsqueeze(0).to(device)  # replace with HuBERT encoding\n",
        "    pros = prosody_proto(B=1, T=units.shape[1])\n",
        "\n",
        "    mel_hat = generator(units, src_logf0.unsqueeze(0).to(device), src_energy.unsqueeze(0).to(device), timbre, pros)\n",
        "\n",
        "    # Griffin-Lim vocoder\n",
        "    wav_out = torchaudio.transforms.GriffinLim(n_fft=1024, hop_length=256)(mel_hat[0].T.exp().cpu())\n",
        "    sf.write(\"converted.wav\", wav_out.numpy(), sr)\n",
        "    return \"converted.wav\"\n",
        "\n",
        "# Example usage (replace with your own files)\n",
        "# out_path = convert_voice(\"source.wav\", \"reference.wav\")\n"
      ],
      "metadata": {
        "id": "yXMP_PMU1Hko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use ProsodyStyleEncoder to compute average prosody vector from target-voice dataset\n",
        "# and initialize prosody_proto.\n",
        "\n",
        "def init_prototype_from_dir(proto, wav_dir, sr=16000):\n",
        "    import os\n",
        "    vecs = []\n",
        "    encoder = ProsodyStyleEncoder().to(device)\n",
        "    for f in os.listdir(wav_dir):\n",
        "        if f.endswith(\".wav\"):\n",
        "            wav, _ = librosa.load(os.path.join(wav_dir, f), sr=sr)\n",
        "            logf0, energy = extract_f0_energy(wav)\n",
        "            vec = encoder(logf0.unsqueeze(0).to(device), energy.unsqueeze(0).to(device))\n",
        "            vecs.append(vec.detach().cpu())\n",
        "    mean_vec = torch.stack(vecs).mean(0)\n",
        "    with torch.no_grad():\n",
        "        proto.proto.copy_(mean_vec.unsqueeze(0))\n",
        "    print(\"Prototype initialized from\", len(vecs), \"files\")\n",
        "\n",
        "# Example:\n",
        "# init_prototype_from_dir(prosody_proto, \"/path/to/target_voice_wavs\")\n"
      ],
      "metadata": {
        "id": "f-PipH3k1LUW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}